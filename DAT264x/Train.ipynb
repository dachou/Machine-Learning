{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load training data\n",
      "Loop over the input images\n",
      "Scale the raw pixel intensities to the range [0, 1]\n",
      "Binarize the labels\n",
      "Partition the data into training and test splits (85/15)\n",
      "Build model\n",
      "Execute training\n",
      "Train on 34000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "34000/34000 [==============================] - 33s 974us/step - loss: 0.3949 - acc: 0.8576 - val_loss: 0.0171 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.39491, saving model to model.h5\n",
      "Epoch 2/20\n",
      "34000/34000 [==============================] - 32s 948us/step - loss: 0.0188 - acc: 0.9945 - val_loss: 0.0054 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00002: loss improved from 0.39491 to 0.01876, saving model to model.h5\n",
      "Epoch 3/20\n",
      "34000/34000 [==============================] - 32s 945us/step - loss: 0.0097 - acc: 0.9973 - val_loss: 0.0119 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00003: loss improved from 0.01876 to 0.00970, saving model to model.h5\n",
      "Epoch 4/20\n",
      "34000/34000 [==============================] - 32s 946us/step - loss: 0.0070 - acc: 0.9977 - val_loss: 0.0058 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00004: loss improved from 0.00970 to 0.00700, saving model to model.h5\n",
      "Epoch 5/20\n",
      "34000/34000 [==============================] - 32s 948us/step - loss: 0.0048 - acc: 0.9985 - val_loss: 0.0070 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00005: loss improved from 0.00700 to 0.00483, saving model to model.h5\n",
      "Epoch 6/20\n",
      "34000/34000 [==============================] - 32s 945us/step - loss: 0.0034 - acc: 0.9990 - val_loss: 0.0052 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00006: loss improved from 0.00483 to 0.00340, saving model to model.h5\n",
      "Epoch 7/20\n",
      "34000/34000 [==============================] - 32s 944us/step - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0046 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00007: loss improved from 0.00340 to 0.00251, saving model to model.h5\n",
      "Epoch 8/20\n",
      "34000/34000 [==============================] - 32s 945us/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0054 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00251\n",
      "Epoch 9/20\n",
      "34000/34000 [==============================] - 32s 945us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.0044 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00009: loss improved from 0.00251 to 0.00174, saving model to model.h5\n",
      "Epoch 10/20\n",
      "34000/34000 [==============================] - 32s 942us/step - loss: 8.0415e-04 - acc: 0.9998 - val_loss: 0.0058 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00010: loss improved from 0.00174 to 0.00080, saving model to model.h5\n",
      "Epoch 11/20\n",
      "34000/34000 [==============================] - 32s 947us/step - loss: 0.0017 - acc: 0.9994 - val_loss: 0.0058 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00080\n",
      "Epoch 12/20\n",
      "34000/34000 [==============================] - 32s 942us/step - loss: 7.9877e-04 - acc: 0.9997 - val_loss: 0.0063 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00012: loss improved from 0.00080 to 0.00080, saving model to model.h5\n",
      "Epoch 13/20\n",
      "34000/34000 [==============================] - 32s 949us/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0052 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00080\n",
      "Epoch 14/20\n",
      "34000/34000 [==============================] - 32s 942us/step - loss: 7.7831e-04 - acc: 0.9998 - val_loss: 0.0073 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00014: loss improved from 0.00080 to 0.00078, saving model to model.h5\n",
      "Epoch 15/20\n",
      "34000/34000 [==============================] - 32s 941us/step - loss: 5.6125e-04 - acc: 0.9999 - val_loss: 0.0061 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00015: loss improved from 0.00078 to 0.00056, saving model to model.h5\n",
      "Epoch 16/20\n",
      "34000/34000 [==============================] - 32s 944us/step - loss: 3.6416e-04 - acc: 0.9999 - val_loss: 0.0060 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00016: loss improved from 0.00056 to 0.00036, saving model to model.h5\n",
      "Epoch 17/20\n",
      "34000/34000 [==============================] - 32s 941us/step - loss: 9.3409e-04 - acc: 0.9996 - val_loss: 0.0049 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00036\n",
      "Epoch 18/20\n",
      "34000/34000 [==============================] - 32s 943us/step - loss: 2.4185e-04 - acc: 0.9999 - val_loss: 0.0079 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00018: loss improved from 0.00036 to 0.00024, saving model to model.h5\n",
      "Epoch 19/20\n",
      "34000/34000 [==============================] - 32s 940us/step - loss: 4.8542e-04 - acc: 0.9998 - val_loss: 0.0070 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00024\n",
      "Epoch 20/20\n",
      "34000/34000 [==============================] - 32s 943us/step - loss: 2.8389e-04 - acc: 0.9999 - val_loss: 0.0071 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00024\n",
      "Test loss: 0.007144838805963256\n",
      "Test accuracy: 0.9991666666666666\n",
      "Wall time: 11min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np \n",
    "import keras \n",
    "import keras \n",
    "from keras.preprocessing.image import img_to_array \n",
    "from sklearn.preprocessing import LabelBinarizer \n",
    "from sklearn.model_selection import train_test_split \n",
    "from keras.models import Sequential, load_model \n",
    "from keras.layers import Dense, Dropout, Flatten \n",
    "from keras.layers import Conv2D, MaxPooling2D \n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from imutils import paths \n",
    "import random \n",
    "import pickle \n",
    "import cv2 \n",
    "import os\n",
    "\n",
    "BatchSize = 128\n",
    "Classes = 4 \n",
    "Epochs = 20 \n",
    "InputShape = (64, 64, 3) \n",
    "data = [] \n",
    "labels = []\n",
    "\n",
    "print(\"Load training data\") \n",
    "imagePaths = sorted(list(paths.list_images('./train/'))) \n",
    "random.seed(42) \n",
    "random.shuffle(imagePaths) \n",
    "\n",
    "print(\"Loop over the input images\")\n",
    "for imagePath in imagePaths: \n",
    "    image = cv2.imread(imagePath, cv2.COLOR_RGB2GRAY) \n",
    "    image = img_to_array(image) \n",
    "    data.append(image) \n",
    "    label = imagePath.split(os.path.sep)[-2].split(\"_\")[0] \n",
    "    # train images are spread across four folders based on their classes \n",
    "    if 'ZERO' in label: \n",
    "        labels.append('ZERO') \n",
    "    if 'ONE' in label: \n",
    "        labels.append('ONE') \n",
    "    if 'TWO' in label: \n",
    "        labels.append('TWO') \n",
    "    if 'THREE' in label: \n",
    "        labels.append('THREE') \n",
    "\n",
    "print(\"Scale the raw pixel intensities to the range [0, 1]\") \n",
    "data = np.array(data, dtype=\"float\") / 255.0 \n",
    "labels = np.array(labels) \n",
    "\n",
    "print(\"Binarize the labels\")\n",
    "mlb = LabelBinarizer() \n",
    "labels = mlb.fit_transform(labels) \n",
    "\n",
    "print(\"Partition the data into training and test splits (85/15)\")\n",
    "(x_train, x_test, y_train, y_test) = train_test_split(data, labels, test_size=0.15, random_state=42) \n",
    "\n",
    "print(\"Build model\")\n",
    "model = Sequential() \n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=InputShape)) \n",
    "model.add(Conv2D(64, (3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.25)) \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(128, activation='relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(Classes, activation='softmax')) \n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "              optimizer=keras.optimizers.Adadelta(), \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "filepath = \"model.h5\" \n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min') \n",
    "callbacks_list = [checkpoint] \n",
    "\n",
    "print(\"Execute training\") \n",
    "model.fit(x_train, y_train, batch_size=BatchSize, epochs=Epochs, verbose=1, \n",
    "          validation_data=(x_test, y_test), callbacks=callbacks_list) \n",
    "score = model.evaluate(x_test, y_test, verbose=0) \n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 419 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# save the model and multi-label binarizer to disk so we can classify our submission later \n",
    "model.save('capstone.model') \n",
    "f = open('capstone.pickle', \"wb\") \n",
    "f.write(pickle.dumps(mlb)) \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
